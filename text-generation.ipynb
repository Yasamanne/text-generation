{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "62fafa81-1725-4907-bfce-cde897dfe286",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:29.747537Z",
          "iopub.status.busy": "2022-12-01T04:18:29.747161Z",
          "iopub.status.idle": "2022-12-01T04:18:29.755457Z",
          "shell.execute_reply": "2022-12-01T04:18:29.754871Z",
          "shell.execute_reply.started": "2022-12-01T04:18:29.747424Z"
        },
        "id": "62fafa81-1725-4907-bfce-cde897dfe286"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Yasaman Emami\"\n",
        "__email__ = ['emami.yasamann@gmail.com','yasaman.emami@sjsu.edu']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvDOrJZsD9gw",
        "outputId": "1dbdc5a1-1e2a-423d-d379-16b68bb5f388"
      },
      "id": "BvDOrJZsD9gw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b522f03b-f881-4124-b9df-ca72bc42d93a",
      "metadata": {
        "id": "b522f03b-f881-4124-b9df-ca72bc42d93a"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6de015c7-1b88-4233-a2f0-ece59e1022e1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:29.757743Z",
          "iopub.status.busy": "2022-12-01T04:18:29.757253Z",
          "iopub.status.idle": "2022-12-01T04:18:29.764182Z",
          "shell.execute_reply": "2022-12-01T04:18:29.763517Z",
          "shell.execute_reply.started": "2022-12-01T04:18:29.757715Z"
        },
        "tags": [],
        "id": "6de015c7-1b88-4233-a2f0-ece59e1022e1"
      },
      "outputs": [],
      "source": [
        "# !pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl\n",
        "# !pip3 install spacy\n",
        "# !pip3 install contractions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn0lhCZcgLM3",
        "outputId": "846cbafe-5408-4ea3-dd18-1323c00e99ac"
      },
      "id": "kn0lhCZcgLM3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 29.6 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 56.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ebba8374-ff18-4781-9e19-25362e0515dd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T22:35:48.495246Z",
          "iopub.status.busy": "2022-12-01T22:35:48.494916Z",
          "iopub.status.idle": "2022-12-01T22:35:48.500158Z",
          "shell.execute_reply": "2022-12-01T22:35:48.499245Z",
          "shell.execute_reply.started": "2022-12-01T22:35:48.495216Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebba8374-ff18-4781-9e19-25362e0515dd",
        "outputId": "6eafdc29-aae5-4f77-edf7-253efd2e5526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "from pickle import dump,load\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU, Activation, Bidirectional\n",
        "import contractions\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop \n",
        "from google.colab import drive\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import gensim\n",
        "import random\n",
        "from keras.layers.core import Dense, SpatialDropout1D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxN-gQRRfyfV",
        "outputId": "96a856f1-e21e-4ee1-8588-f2d6cab16cf9"
      },
      "id": "TxN-gQRRfyfV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b74b5d4-1e7b-4a6e-8146-b7cdb5409ae7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.886018Z",
          "iopub.status.busy": "2022-12-01T04:18:39.885694Z",
          "iopub.status.idle": "2022-12-01T04:18:39.892235Z",
          "shell.execute_reply": "2022-12-01T04:18:39.890736Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.885987Z"
        },
        "tags": [],
        "id": "4b74b5d4-1e7b-4a6e-8146-b7cdb5409ae7"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/gdrive/MyDrive/HW5/data.txt\"\n",
        "\n",
        "with open(filepath) as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "WOegpG5fV1AT"
      },
      "id": "WOegpG5fV1AT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.c. Expand Contaction"
      ],
      "metadata": {
        "id": "mh5Yi1blV6Ic"
      },
      "id": "mh5Yi1blV6Ic"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "af6a453a-f0ab-42c2-920e-7d9d92a3c792",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.896333Z",
          "iopub.status.busy": "2022-12-01T04:18:39.894448Z",
          "iopub.status.idle": "2022-12-01T04:18:39.910224Z",
          "shell.execute_reply": "2022-12-01T04:18:39.909251Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.896285Z"
        },
        "tags": [],
        "id": "af6a453a-f0ab-42c2-920e-7d9d92a3c792"
      },
      "outputs": [],
      "source": [
        "text = contractions.fix(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.b. Convert to lowercase"
      ],
      "metadata": {
        "id": "ZAT_eRUJWBvc"
      },
      "id": "ZAT_eRUJWBvc"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "615a724b-a56e-4168-869a-a229989aa13a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.934788Z",
          "iopub.status.busy": "2022-12-01T04:18:39.934326Z",
          "iopub.status.idle": "2022-12-01T04:18:39.941369Z",
          "shell.execute_reply": "2022-12-01T04:18:39.940046Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.934751Z"
        },
        "tags": [],
        "id": "615a724b-a56e-4168-869a-a229989aa13a"
      },
      "outputs": [],
      "source": [
        "text = text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "310c4830-4608-41bc-83e0-8de0eeb95c78",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.944492Z",
          "iopub.status.busy": "2022-12-01T04:18:39.943520Z",
          "iopub.status.idle": "2022-12-01T04:18:39.955415Z",
          "shell.execute_reply": "2022-12-01T04:18:39.954358Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.944447Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "310c4830-4608-41bc-83e0-8de0eeb95c78"
      },
      "outputs": [],
      "source": [
        "# text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.e. Stemming"
      ],
      "metadata": {
        "id": "sRDIYBvXWHpB"
      },
      "id": "sRDIYBvXWHpB"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ac3d425d-19c8-4264-a5b6-7623a6db4c1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.957242Z",
          "iopub.status.busy": "2022-12-01T04:18:39.956716Z",
          "iopub.status.idle": "2022-12-01T04:18:39.963019Z",
          "shell.execute_reply": "2022-12-01T04:18:39.961901Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.957200Z"
        },
        "tags": [],
        "id": "ac3d425d-19c8-4264-a5b6-7623a6db4c1a"
      },
      "outputs": [],
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "text = porter_stemmer.stem(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.e. Lemmatizing"
      ],
      "metadata": {
        "id": "tf8rLopXWOG5"
      },
      "id": "tf8rLopXWOG5"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f1bae0d8-4971-4482-be01-8c6aa11d0ac9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:39.969430Z",
          "iopub.status.busy": "2022-12-01T04:18:39.969121Z",
          "iopub.status.idle": "2022-12-01T04:18:41.559683Z",
          "shell.execute_reply": "2022-12-01T04:18:41.558985Z",
          "shell.execute_reply.started": "2022-12-01T04:18:39.969389Z"
        },
        "tags": [],
        "id": "f1bae0d8-4971-4482-be01-8c6aa11d0ac9"
      },
      "outputs": [],
      "source": [
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = wordnet_lemmatizer.lemmatize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.a. Tokenizing"
      ],
      "metadata": {
        "id": "vhCXDaoXWXEr"
      },
      "id": "vhCXDaoXWXEr"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "364f1fa0-ec5a-466c-a2ea-dad9bbc9765e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:41.561501Z",
          "iopub.status.busy": "2022-12-01T04:18:41.560929Z",
          "iopub.status.idle": "2022-12-01T04:18:44.702267Z",
          "shell.execute_reply": "2022-12-01T04:18:44.701295Z",
          "shell.execute_reply.started": "2022-12-01T04:18:41.561458Z"
        },
        "tags": [],
        "id": "364f1fa0-ec5a-466c-a2ea-dad9bbc9765e"
      },
      "outputs": [],
      "source": [
        "spcay_tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "spcay_tokenizer = spcay_tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "14f4d678-c682-464d-8b79-27dda3783451",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:44.703833Z",
          "iopub.status.busy": "2022-12-01T04:18:44.703441Z",
          "iopub.status.idle": "2022-12-01T04:18:44.724952Z",
          "shell.execute_reply": "2022-12-01T04:18:44.724219Z",
          "shell.execute_reply.started": "2022-12-01T04:18:44.703791Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "14f4d678-c682-464d-8b79-27dda3783451"
      },
      "outputs": [],
      "source": [
        "# spcay_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.d. remove punctuation"
      ],
      "metadata": {
        "id": "knb7ppc3Wp7w"
      },
      "id": "knb7ppc3Wp7w"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "294f92fe-b395-478f-8838-7d39137158b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:44.726327Z",
          "iopub.status.busy": "2022-12-01T04:18:44.725947Z",
          "iopub.status.idle": "2022-12-01T04:18:44.744178Z",
          "shell.execute_reply": "2022-12-01T04:18:44.742342Z",
          "shell.execute_reply.started": "2022-12-01T04:18:44.726285Z"
        },
        "tags": [],
        "id": "294f92fe-b395-478f-8838-7d39137158b7"
      },
      "outputs": [],
      "source": [
        "tokens = [t.text.lower() for t in spcay_tokenizer if t.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b2b39bb2-84eb-4bc0-82fa-c704138ecfad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T22:37:56.013173Z",
          "iopub.status.busy": "2022-12-01T22:37:56.012672Z",
          "iopub.status.idle": "2022-12-01T22:37:56.036747Z",
          "shell.execute_reply": "2022-12-01T22:37:56.035494Z",
          "shell.execute_reply.started": "2022-12-01T22:37:56.013146Z"
        },
        "tags": [],
        "id": "b2b39bb2-84eb-4bc0-82fa-c704138ecfad"
      },
      "outputs": [],
      "source": [
        "# take first 45 words for x seq and 46th word as y\n",
        "seq_len = 46\n",
        "seq = []\n",
        "for i in range(seq_len, len(tokens)):\n",
        "    each_seq = tokens[i-seq_len:i]\n",
        "    seq.append(each_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d4eb292a-67f2-4d52-85f1-bf81d3d61ec6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:44.783371Z",
          "iopub.status.busy": "2022-12-01T04:18:44.783123Z",
          "iopub.status.idle": "2022-12-01T04:18:44.788060Z",
          "shell.execute_reply": "2022-12-01T04:18:44.787333Z",
          "shell.execute_reply.started": "2022-12-01T04:18:44.783346Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "d4eb292a-67f2-4d52-85f1-bf81d3d61ec6",
        "outputId": "81633fe0-3b8f-4a6b-c8ea-c2241625572c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world it is a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\" \".join(seq[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_HeInnztgsl",
        "outputId": "1a4622d8-34f3-4288-a24d-ee98ca503d62"
      },
      "id": "w_HeInnztgsl",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11303"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max=int(len(seq)*.75)\n",
        "seq=seq[:max]"
      ],
      "metadata": {
        "id": "b3rZhV4stouU"
      },
      "id": "b3rZhV4stouU",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d7fcab5e-fb6e-477a-b449-136243ae9c46",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:44.789102Z",
          "iopub.status.busy": "2022-12-01T04:18:44.788948Z",
          "iopub.status.idle": "2022-12-01T04:18:45.123472Z",
          "shell.execute_reply": "2022-12-01T04:18:45.122828Z",
          "shell.execute_reply.started": "2022-12-01T04:18:44.789081Z"
        },
        "tags": [],
        "id": "d7fcab5e-fb6e-477a-b449-136243ae9c46"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b0b3db47-4f9d-44e9-9da7-195e6bd21ad0",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:45.124898Z",
          "iopub.status.busy": "2022-12-01T04:18:45.124489Z",
          "iopub.status.idle": "2022-12-01T04:18:45.180249Z",
          "shell.execute_reply": "2022-12-01T04:18:45.179483Z",
          "shell.execute_reply.started": "2022-12-01T04:18:45.124851Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "b0b3db47-4f9d-44e9-9da7-195e6bd21ad0"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = tokenizer.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "bf70190f-e01e-4952-b988-51b647db17bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:45.218864Z",
          "iopub.status.busy": "2022-12-01T04:18:45.218629Z",
          "iopub.status.idle": "2022-12-01T04:18:45.425368Z",
          "shell.execute_reply": "2022-12-01T04:18:45.424442Z",
          "shell.execute_reply.started": "2022-12-01T04:18:45.218839Z"
        },
        "tags": [],
        "id": "bf70190f-e01e-4952-b988-51b647db17bd"
      },
      "outputs": [],
      "source": [
        "seq_all = tokenizer.texts_to_sequences(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a28927f2-b0df-4482-bf89-35a0c553a262",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:45.426649Z",
          "iopub.status.busy": "2022-12-01T04:18:45.426368Z",
          "iopub.status.idle": "2022-12-01T04:18:46.018690Z",
          "shell.execute_reply": "2022-12-01T04:18:46.017945Z",
          "shell.execute_reply.started": "2022-12-01T04:18:45.426623Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "a28927f2-b0df-4482-bf89-35a0c553a262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439d42b6-e90a-4384-fe43-280fb506bb50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8477"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(seq_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f2b05c0a-7bae-4b4d-b6b4-39e1ec0c98b0",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:45.182119Z",
          "iopub.status.busy": "2022-12-01T04:18:45.181763Z",
          "iopub.status.idle": "2022-12-01T04:18:45.217207Z",
          "shell.execute_reply": "2022-12-01T04:18:45.216494Z",
          "shell.execute_reply.started": "2022-12-01T04:18:45.182074Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "f2b05c0a-7bae-4b4d-b6b4-39e1ec0c98b0"
      },
      "outputs": [],
      "source": [
        "#token indices\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "63b4a213-efd1-4088-8a33-7783120ff093",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:46.020055Z",
          "iopub.status.busy": "2022-12-01T04:18:46.019717Z",
          "iopub.status.idle": "2022-12-01T04:18:46.100845Z",
          "shell.execute_reply": "2022-12-01T04:18:46.100110Z",
          "shell.execute_reply.started": "2022-12-01T04:18:46.020029Z"
        },
        "tags": [],
        "id": "63b4a213-efd1-4088-8a33-7783120ff093"
      },
      "outputs": [],
      "source": [
        "seq_all = np.array(seq_all) # converting to numpy array\n",
        "\n",
        "X = seq_all[:,:-1]\n",
        "y = seq_all[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fe81b827-ca6e-4b29-b641-8bbfa2064a87",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:46.102434Z",
          "iopub.status.busy": "2022-12-01T04:18:46.101909Z",
          "iopub.status.idle": "2022-12-01T04:18:46.106750Z",
          "shell.execute_reply": "2022-12-01T04:18:46.106204Z",
          "shell.execute_reply.started": "2022-12-01T04:18:46.102393Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe81b827-ca6e-4b29-b641-8bbfa2064a87",
        "outputId": "cefdbba0-690e-46bc-8dda-6a8b07d3301e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8477,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "88179b48-2ce5-4869-bf10-8dd47f70f5d2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:46.141300Z",
          "iopub.status.busy": "2022-12-01T04:18:46.140933Z",
          "iopub.status.idle": "2022-12-01T04:18:46.161881Z",
          "shell.execute_reply": "2022-12-01T04:18:46.161170Z",
          "shell.execute_reply.started": "2022-12-01T04:18:46.141246Z"
        },
        "tags": [],
        "id": "88179b48-2ce5-4869-bf10-8dd47f70f5d2"
      },
      "outputs": [],
      "source": [
        "voc_size = len(tokenizer.word_counts) # number of unique words\n",
        "y = to_categorical(y, num_classes= voc_size+1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9a2958ec-2f2a-4031-9ec9-1ef370a16eb7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:46.108018Z",
          "iopub.status.busy": "2022-12-01T04:18:46.107808Z",
          "iopub.status.idle": "2022-12-01T04:18:46.139957Z",
          "shell.execute_reply": "2022-12-01T04:18:46.139247Z",
          "shell.execute_reply.started": "2022-12-01T04:18:46.107993Z"
        },
        "tags": [],
        "id": "9a2958ec-2f2a-4031-9ec9-1ef370a16eb7"
      },
      "outputs": [],
      "source": [
        "maxlen = 200\n",
        "X_train_pad = pad_sequences(X, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "952db8f8-5759-4c04-8100-65c4e724ede4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T04:18:46.163386Z",
          "iopub.status.busy": "2022-12-01T04:18:46.163021Z",
          "iopub.status.idle": "2022-12-01T04:18:46.168809Z",
          "shell.execute_reply": "2022-12-01T04:18:46.168167Z",
          "shell.execute_reply.started": "2022-12-01T04:18:46.163359Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952db8f8-5759-4c04-8100-65c4e724ede4",
        "outputId": "4388c3b9-d0ca-4f91-8255-ce778b5cc8e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8477, 45), (8477, 2245))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = X.shape[1]"
      ],
      "metadata": {
        "id": "RFxZQ0PjqgCh"
      },
      "id": "RFxZQ0PjqgCh",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R1J4H2VqhQe",
        "outputId": "d41d99d6-4936-4ed0-f99c-731928c84b02"
      },
      "id": "1R1J4H2VqhQe",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Text Generation model with keras Embedding layer"
      ],
      "metadata": {
        "id": "HzYAXR_QVnJv"
      },
      "id": "HzYAXR_QVnJv"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential(name=\"keras-embedding\")\n",
        "    model.add(Embedding(voc_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "QkpCXEa3qS8F"
      },
      "id": "QkpCXEa3qS8F",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_model = create_model(voc_size+1, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtoxqM7JqoGc",
        "outputId": "8d4747be-e722-4be7-f3f4-fa13bcedf773"
      },
      "id": "xtoxqM7JqoGc",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 45, 25)            56100     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 45, 150)           105600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 150)               22650     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2245)              338995    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 703,945\n",
            "Trainable params: 703,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_model.fit(X, y, batch_size=512, epochs=300,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOzF2DXaquBj",
        "outputId": "f8f82549-2b1a-4fcb-ea7f-05108c9dd464"
      },
      "id": "QOzF2DXaquBj",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "17/17 [==============================] - 16s 33ms/step - loss: 7.3704 - accuracy: 0.0500\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.4335 - accuracy: 0.0512\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.2931 - accuracy: 0.0552\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2576 - accuracy: 0.0552\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.2483 - accuracy: 0.0552\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2424 - accuracy: 0.0552\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.2400 - accuracy: 0.0552\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2395 - accuracy: 0.0552\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2395 - accuracy: 0.0552\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2374 - accuracy: 0.0552\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2347 - accuracy: 0.0552\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2311 - accuracy: 0.0552\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.2232 - accuracy: 0.0552\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 6.1946 - accuracy: 0.0552\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.1244 - accuracy: 0.0552\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 6.0425 - accuracy: 0.0552\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.9916 - accuracy: 0.0552\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.9561 - accuracy: 0.0564\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.9131 - accuracy: 0.0560\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 5.8660 - accuracy: 0.0658\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.8037 - accuracy: 0.0648\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.7362 - accuracy: 0.0669\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.6736 - accuracy: 0.0703\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.6228 - accuracy: 0.0700\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.5777 - accuracy: 0.0751\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.5335 - accuracy: 0.0744\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.4846 - accuracy: 0.0741\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.4392 - accuracy: 0.0768\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.4001 - accuracy: 0.0781\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.3542 - accuracy: 0.0763\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 5.3132 - accuracy: 0.0783\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.2760 - accuracy: 0.0815\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.2366 - accuracy: 0.0807\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.1980 - accuracy: 0.0815\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.1634 - accuracy: 0.0856\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.1311 - accuracy: 0.0853\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.0997 - accuracy: 0.0852\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.0710 - accuracy: 0.0867\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.0465 - accuracy: 0.0875\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 5.0242 - accuracy: 0.0875\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.9967 - accuracy: 0.0881\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.9729 - accuracy: 0.0880\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.9520 - accuracy: 0.0908\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.9279 - accuracy: 0.0906\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.9028 - accuracy: 0.0911\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.8822 - accuracy: 0.0937\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.8599 - accuracy: 0.0910\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.8371 - accuracy: 0.0927\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.8145 - accuracy: 0.0950\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.7921 - accuracy: 0.0934\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.7670 - accuracy: 0.0966\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.7482 - accuracy: 0.0989\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.7092 - accuracy: 0.0981\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.6781 - accuracy: 0.0970\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.6550 - accuracy: 0.0997\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.6313 - accuracy: 0.1023\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.6038 - accuracy: 0.1006\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.5777 - accuracy: 0.1043\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.5511 - accuracy: 0.1076\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.5335 - accuracy: 0.1077\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.5100 - accuracy: 0.1050\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.4791 - accuracy: 0.1103\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.4567 - accuracy: 0.1117\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.4332 - accuracy: 0.1137\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.4132 - accuracy: 0.1128\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.4030 - accuracy: 0.1124\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.3804 - accuracy: 0.1119\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.3551 - accuracy: 0.1191\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.3327 - accuracy: 0.1176\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.3141 - accuracy: 0.1219\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.2873 - accuracy: 0.1221\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.2666 - accuracy: 0.1181\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.2457 - accuracy: 0.1223\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.2291 - accuracy: 0.1237\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.2154 - accuracy: 0.1283\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.1942 - accuracy: 0.1249\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.1760 - accuracy: 0.1276\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.1504 - accuracy: 0.1308\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.1403 - accuracy: 0.1312\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.1121 - accuracy: 0.1359\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.0917 - accuracy: 0.1335\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.0771 - accuracy: 0.1344\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.0597 - accuracy: 0.1381\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 4.0332 - accuracy: 0.1421\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.0161 - accuracy: 0.1398\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 4.0035 - accuracy: 0.1412\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.9781 - accuracy: 0.1449\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.9599 - accuracy: 0.1455\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.9423 - accuracy: 0.1418\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.9204 - accuracy: 0.1465\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.9001 - accuracy: 0.1516\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.8956 - accuracy: 0.1508\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.8773 - accuracy: 0.1532\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.8614 - accuracy: 0.1534\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.8357 - accuracy: 0.1550\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.8187 - accuracy: 0.1603\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.7923 - accuracy: 0.1679\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.7856 - accuracy: 0.1587\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.7641 - accuracy: 0.1610\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 1s 35ms/step - loss: 3.7380 - accuracy: 0.1673\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 3.7195 - accuracy: 0.1698\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 1s 33ms/step - loss: 3.7039 - accuracy: 0.1699\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.6877 - accuracy: 0.1767\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 1s 34ms/step - loss: 3.6763 - accuracy: 0.1716\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 3.6574 - accuracy: 0.1746\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.6314 - accuracy: 0.1767\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.6080 - accuracy: 0.1837\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.6021 - accuracy: 0.1826\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.5789 - accuracy: 0.1847\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.5613 - accuracy: 0.1891\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.5477 - accuracy: 0.1903\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.5431 - accuracy: 0.1878\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.5156 - accuracy: 0.1951\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4885 - accuracy: 0.1952\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4744 - accuracy: 0.2007\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4634 - accuracy: 0.1996\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4472 - accuracy: 0.1972\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4272 - accuracy: 0.2037\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4072 - accuracy: 0.2038\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.3894 - accuracy: 0.2156\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.3773 - accuracy: 0.2146\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.3617 - accuracy: 0.2122\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.3331 - accuracy: 0.2197\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.3269 - accuracy: 0.2221\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.3074 - accuracy: 0.2237\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.2930 - accuracy: 0.2305\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.2898 - accuracy: 0.2303\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.2991 - accuracy: 0.2239\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 3.3217 - accuracy: 0.2134\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.6666 - accuracy: 0.1958\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 3.6185 - accuracy: 0.1786\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.4514 - accuracy: 0.1984\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.3537 - accuracy: 0.2194\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.3189 - accuracy: 0.2264\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.2766 - accuracy: 0.2297\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.2336 - accuracy: 0.2386\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 3.2047 - accuracy: 0.2431\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.1802 - accuracy: 0.2493\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.1554 - accuracy: 0.2545\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 3.1378 - accuracy: 0.2563\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.1206 - accuracy: 0.2638\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 3.0993 - accuracy: 0.2631\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.0809 - accuracy: 0.2703\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.0675 - accuracy: 0.2725\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.0450 - accuracy: 0.2736\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.0261 - accuracy: 0.2766\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 3.0129 - accuracy: 0.2818\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.9932 - accuracy: 0.2902\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.9804 - accuracy: 0.2852\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 2.9708 - accuracy: 0.2920\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.9488 - accuracy: 0.2963\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.9311 - accuracy: 0.2996\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 2.9139 - accuracy: 0.3020\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.9008 - accuracy: 0.3053\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.8953 - accuracy: 0.3062\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.8704 - accuracy: 0.3121\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.8495 - accuracy: 0.3140\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.8409 - accuracy: 0.3137\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.8286 - accuracy: 0.3186\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.8144 - accuracy: 0.3216\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7919 - accuracy: 0.3274\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7753 - accuracy: 0.3333\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7580 - accuracy: 0.3329\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7484 - accuracy: 0.3383\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7322 - accuracy: 0.3413\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.7092 - accuracy: 0.3454\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.6983 - accuracy: 0.3465\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.6953 - accuracy: 0.3487\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.6789 - accuracy: 0.3548\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.6627 - accuracy: 0.3520\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.6447 - accuracy: 0.3586\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.6290 - accuracy: 0.3655\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.6152 - accuracy: 0.3656\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.6022 - accuracy: 0.3691\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.5962 - accuracy: 0.3682\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.5744 - accuracy: 0.3802\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.5610 - accuracy: 0.3760\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.5434 - accuracy: 0.3802\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.5342 - accuracy: 0.3855\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.5228 - accuracy: 0.3868\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.5176 - accuracy: 0.3896\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.4942 - accuracy: 0.3961\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.4818 - accuracy: 0.3968\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.4729 - accuracy: 0.3913\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.4570 - accuracy: 0.4007\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.4397 - accuracy: 0.4053\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.4275 - accuracy: 0.4090\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.4216 - accuracy: 0.4080\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.4107 - accuracy: 0.4097\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.3919 - accuracy: 0.4175\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3849 - accuracy: 0.4194\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.3685 - accuracy: 0.4147\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3547 - accuracy: 0.4234\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3437 - accuracy: 0.4250\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.3327 - accuracy: 0.4295\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3259 - accuracy: 0.4280\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3223 - accuracy: 0.4272\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.3069 - accuracy: 0.4327\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2859 - accuracy: 0.4367\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.2720 - accuracy: 0.4471\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2644 - accuracy: 0.4439\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.2562 - accuracy: 0.4463\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2407 - accuracy: 0.4487\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2323 - accuracy: 0.4531\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2156 - accuracy: 0.4558\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.2065 - accuracy: 0.4566\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1899 - accuracy: 0.4625\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1806 - accuracy: 0.4679\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1738 - accuracy: 0.4627\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1611 - accuracy: 0.4662\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.1469 - accuracy: 0.4684\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1554 - accuracy: 0.4667\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1404 - accuracy: 0.4671\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.1175 - accuracy: 0.4798\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1129 - accuracy: 0.4805\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.1032 - accuracy: 0.4795\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0888 - accuracy: 0.4858\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0791 - accuracy: 0.4834\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 2.0678 - accuracy: 0.4909\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0601 - accuracy: 0.4900\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0448 - accuracy: 0.4984\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 2.0425 - accuracy: 0.4963\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0355 - accuracy: 0.4932\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 2.0282 - accuracy: 0.4911\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0115 - accuracy: 0.5029\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0045 - accuracy: 0.4983\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 2.0004 - accuracy: 0.5010\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9869 - accuracy: 0.5057\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9757 - accuracy: 0.5095\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9627 - accuracy: 0.5113\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9536 - accuracy: 0.5128\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9431 - accuracy: 0.5185\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9361 - accuracy: 0.5175\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9215 - accuracy: 0.5281\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9134 - accuracy: 0.5238\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.9148 - accuracy: 0.5206\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.9104 - accuracy: 0.5214\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 30ms/step - loss: 1.9017 - accuracy: 0.5239\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8941 - accuracy: 0.5265\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8797 - accuracy: 0.5318\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8722 - accuracy: 0.5299\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8694 - accuracy: 0.5304\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.8529 - accuracy: 0.5429\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.8438 - accuracy: 0.5383\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8340 - accuracy: 0.5428\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.8211 - accuracy: 0.5421\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.8205 - accuracy: 0.5429\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.8033 - accuracy: 0.5505\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7937 - accuracy: 0.5531\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.7875 - accuracy: 0.5524\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7793 - accuracy: 0.5563\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7765 - accuracy: 0.5533\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.7793 - accuracy: 0.5539\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7604 - accuracy: 0.5629\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.7661 - accuracy: 0.5527\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7635 - accuracy: 0.5575\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.7480 - accuracy: 0.5608\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7389 - accuracy: 0.5634\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7220 - accuracy: 0.5693\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7113 - accuracy: 0.5705\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.7025 - accuracy: 0.5707\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6985 - accuracy: 0.5751\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6905 - accuracy: 0.5777\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6777 - accuracy: 0.5820\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.6665 - accuracy: 0.5810\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6633 - accuracy: 0.5790\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6625 - accuracy: 0.5779\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 28ms/step - loss: 1.6515 - accuracy: 0.5903\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.6431 - accuracy: 0.5902\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.6272 - accuracy: 0.5891\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.6223 - accuracy: 0.5910\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6105 - accuracy: 0.5974\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.6070 - accuracy: 0.5976\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.6012 - accuracy: 0.6012\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.5951 - accuracy: 0.6035\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5862 - accuracy: 0.6040\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.5796 - accuracy: 0.6038\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5736 - accuracy: 0.5994\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5677 - accuracy: 0.6071\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 1.5503 - accuracy: 0.6088\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5441 - accuracy: 0.6065\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5503 - accuracy: 0.6092\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.5481 - accuracy: 0.6108\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5319 - accuracy: 0.6102\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.5247 - accuracy: 0.6158\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5153 - accuracy: 0.6185\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5229 - accuracy: 0.6207\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5231 - accuracy: 0.6197\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.5011 - accuracy: 0.6201\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4858 - accuracy: 0.6249\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4891 - accuracy: 0.6233\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4777 - accuracy: 0.6237\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4675 - accuracy: 0.6309\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.4617 - accuracy: 0.6322\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 1s 29ms/step - loss: 1.4552 - accuracy: 0.6338\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4439 - accuracy: 0.6349\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4400 - accuracy: 0.6345\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4330 - accuracy: 0.6434\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 1.4274 - accuracy: 0.6383\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 1.4169 - accuracy: 0.6424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f904d26eca0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. Text Generation with Glove word Embedding\n"
      ],
      "metadata": {
        "id": "JoSoM1tMO8C5"
      },
      "id": "JoSoM1tMO8C5"
    },
    {
      "cell_type": "code",
      "source": [
        "## Glove\n",
        "glove_dir = '/content/gdrive/MyDrive/HW5/glove.6B.100d.txt'\n",
        "\n",
        "embedings = {}\n",
        "with open(glove_dir) as f:\n",
        "    data = f.readlines()\n",
        "    \n",
        "embeddings = {}\n",
        "for line in data:\n",
        "    word = line.split()[0]\n",
        "    embeddings[word] = np.asarray(line.split()[1:],dtype='float32')"
      ],
      "metadata": {
        "id": "-8bqYpzDPA-i"
      },
      "id": "-8bqYpzDPA-i",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 45\n",
        "embedding_dim = 100\n",
        "xtrain = pad_sequences(X,maxlen=max_len)"
      ],
      "metadata": {
        "id": "hFYVbEAvPFmm"
      },
      "id": "hFYVbEAvPFmm",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "max_features = len(word_index)\n",
        "embedding_matrix = np.zeros((len(vocabulary_size)+1,embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i < max_features:\n",
        "        \n",
        "        embedding_vector = embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # we found the word - add that words vector to the matrix\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "JPIma2caPFi9"
      },
      "id": "JPIma2caPFi9",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmMbVqnrRZK4",
        "outputId": "09d58ab8-dedd-4a11-e26d-db9c0c3ff0ea"
      },
      "id": "WmMbVqnrRZK4",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2245, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-bUba4ZTjkl",
        "outputId": "8d2f2d2b-e6dc-4ade-d01f-04fcd8576d66"
      },
      "id": "h-bUba4ZTjkl",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2244"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b_yXq_HTmmt",
        "outputId": "6294dde3-e876-45f6-e577-decfe9ca4976"
      },
      "id": "7b_yXq_HTmmt",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2244"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def glove_model():\n",
        "   \n",
        "    model = Sequential(name=\"Glove\")\n",
        "\n",
        "    # model.add(Embedding(len(X),\n",
        "    #                     100,\n",
        "    #                     input_length=max_len))\n",
        "\n",
        "    model.add(Embedding(len(vocabulary_size)+1 , 100,\n",
        "                                weights = [embedding_matrix],\n",
        "                                input_length = 45 , \n",
        "                                trainable = False))\n",
        "    # # model.add(Dense(100))\n",
        "    # model.add(Dense(16,activation='relu'))\n",
        "    # # model.add(Dropout(0.50))\n",
        "    # # model.add(Dense(16,activation='relu'))\n",
        "    # # model.add(Dropout(0.20))\n",
        "\n",
        "\n",
        "    model.add(LSTM(10,return_sequences=True))\n",
        "    model.add(LSTM(10))# model.add(LSTM(10))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "    model.add(Dense(len(vocabulary_size)+1, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    opt = RMSprop(lr=0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "veO0Sc4rPFfs"
      },
      "id": "veO0Sc4rPFfs",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_model = glove_model()\n",
        "g_model.fit(xtrain, y, epochs=300, batch_size=256, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE9GhqSla8tE",
        "outputId": "a7ec474a-f1ba-4b50-9825-65803dab562f"
      },
      "id": "UE9GhqSla8tE",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Glove\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 45, 100)           224500    \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 45, 10)            4440      \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 10)                840       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               2816      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 2245)              2301125   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,190,617\n",
            "Trainable params: 2,966,117\n",
            "Non-trainable params: 224,500\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 4s 14ms/step - loss: 6.6799 - accuracy: 0.0524\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.3208 - accuracy: 0.0552\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2968 - accuracy: 0.0552\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2905 - accuracy: 0.0552\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2883 - accuracy: 0.0552\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.2742 - accuracy: 0.0552\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2718 - accuracy: 0.0552\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2699 - accuracy: 0.0552\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.2584 - accuracy: 0.0552\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2590 - accuracy: 0.0552\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2569 - accuracy: 0.0552\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2541 - accuracy: 0.0552\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2489 - accuracy: 0.0552\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2470 - accuracy: 0.0552\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.2439 - accuracy: 0.0552\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2414 - accuracy: 0.0552\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2406 - accuracy: 0.0552\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2382 - accuracy: 0.0552\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2340 - accuracy: 0.0552\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2313 - accuracy: 0.0552\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2240 - accuracy: 0.0552\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2177 - accuracy: 0.0552\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2140 - accuracy: 0.0552\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2070 - accuracy: 0.0552\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.1913 - accuracy: 0.0552\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.1881 - accuracy: 0.0552\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.1573 - accuracy: 0.0558\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.1099 - accuracy: 0.0583\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.0602 - accuracy: 0.0597\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.0247 - accuracy: 0.0610\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 6.0043 - accuracy: 0.0617\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9782 - accuracy: 0.0617\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9686 - accuracy: 0.0616\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9501 - accuracy: 0.0616\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9351 - accuracy: 0.0622\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9137 - accuracy: 0.0623\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9062 - accuracy: 0.0621\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8863 - accuracy: 0.0638\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8717 - accuracy: 0.0629\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8549 - accuracy: 0.0636\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8426 - accuracy: 0.0637\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8293 - accuracy: 0.0638\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.8168 - accuracy: 0.0645\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.8040 - accuracy: 0.0643\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7954 - accuracy: 0.0650\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7801 - accuracy: 0.0652\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7735 - accuracy: 0.0635\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.7621 - accuracy: 0.0639\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7552 - accuracy: 0.0651\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7410 - accuracy: 0.0650\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7349 - accuracy: 0.0646\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7234 - accuracy: 0.0665\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7194 - accuracy: 0.0649\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.7059 - accuracy: 0.0650\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6966 - accuracy: 0.0650\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6898 - accuracy: 0.0651\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6817 - accuracy: 0.0654\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.6680 - accuracy: 0.0654\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6655 - accuracy: 0.0663\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.6566 - accuracy: 0.0667\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6489 - accuracy: 0.0658\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6401 - accuracy: 0.0675\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.6260 - accuracy: 0.0667\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6200 - accuracy: 0.0667\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6128 - accuracy: 0.0670\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.6025 - accuracy: 0.0670\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5857 - accuracy: 0.0682\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5732 - accuracy: 0.0681\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5572 - accuracy: 0.0684\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5315 - accuracy: 0.0679\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5109 - accuracy: 0.0684\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.4839 - accuracy: 0.0682\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.4640 - accuracy: 0.0671\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.4444 - accuracy: 0.0683\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.4236 - accuracy: 0.0685\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.3996 - accuracy: 0.0687\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.3789 - accuracy: 0.0689\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.3634 - accuracy: 0.0684\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 5.3364 - accuracy: 0.0701\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.3161 - accuracy: 0.0701\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 5.2897 - accuracy: 0.0702\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.2775 - accuracy: 0.0694\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.2534 - accuracy: 0.0695\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.2333 - accuracy: 0.0710\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.2102 - accuracy: 0.0714\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.1853 - accuracy: 0.0698\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 5.1695 - accuracy: 0.0704\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.1493 - accuracy: 0.0697\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.1242 - accuracy: 0.0705\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 5.1054 - accuracy: 0.0696\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.0806 - accuracy: 0.0709\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.0569 - accuracy: 0.0729\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.0341 - accuracy: 0.0697\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 5.0206 - accuracy: 0.0714\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.0016 - accuracy: 0.0716\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.9701 - accuracy: 0.0721\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.9552 - accuracy: 0.0715\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.9323 - accuracy: 0.0711\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.8958 - accuracy: 0.0737\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.8853 - accuracy: 0.0708\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.8631 - accuracy: 0.0723\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.8332 - accuracy: 0.0757\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.8173 - accuracy: 0.0733\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.7851 - accuracy: 0.0744\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.7721 - accuracy: 0.0751\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.7330 - accuracy: 0.0756\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.7270 - accuracy: 0.0740\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.6952 - accuracy: 0.0755\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.6689 - accuracy: 0.0763\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.6396 - accuracy: 0.0770\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.6206 - accuracy: 0.0779\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.5910 - accuracy: 0.0786\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.5638 - accuracy: 0.0788\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.5387 - accuracy: 0.0775\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.5035 - accuracy: 0.0810\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.4859 - accuracy: 0.0821\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.4578 - accuracy: 0.0792\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 4.4215 - accuracy: 0.0808\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 4.3957 - accuracy: 0.0851\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 4.3636 - accuracy: 0.0814\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.3623 - accuracy: 0.0820\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 4.3316 - accuracy: 0.0823\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 4.3004 - accuracy: 0.0860\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 4.2600 - accuracy: 0.0880\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.2545 - accuracy: 0.0853\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 4.2088 - accuracy: 0.0879\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 4.2050 - accuracy: 0.0853\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 4.1789 - accuracy: 0.0846\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 4.1580 - accuracy: 0.0924\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 4.1244 - accuracy: 0.0952\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 4.1196 - accuracy: 0.0937\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.0704 - accuracy: 0.0935\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.0587 - accuracy: 0.0931\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.0696 - accuracy: 0.0965\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.0247 - accuracy: 0.0960\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.0038 - accuracy: 0.0964\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.9908 - accuracy: 0.0937\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.9679 - accuracy: 0.1002\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.9571 - accuracy: 0.1035\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.9291 - accuracy: 0.1052\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.9030 - accuracy: 0.1006\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.8991 - accuracy: 0.1032\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.8768 - accuracy: 0.1068\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.8766 - accuracy: 0.1066\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 3.8286 - accuracy: 0.1092\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 3.8365 - accuracy: 0.1086\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 3.8173 - accuracy: 0.1057\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.8064 - accuracy: 0.1055\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.7627 - accuracy: 0.1153\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.7869 - accuracy: 0.1137\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.7537 - accuracy: 0.1158\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.7340 - accuracy: 0.1135\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.7173 - accuracy: 0.1131\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.7178 - accuracy: 0.1148\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.6912 - accuracy: 0.1189\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.6670 - accuracy: 0.1202\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.6722 - accuracy: 0.1174\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.6666 - accuracy: 0.1245\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.6403 - accuracy: 0.1246\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.6263 - accuracy: 0.1212\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5919 - accuracy: 0.1373\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5908 - accuracy: 0.1340\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5953 - accuracy: 0.1258\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5584 - accuracy: 0.1375\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.5684 - accuracy: 0.1317\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.5258 - accuracy: 0.1355\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5255 - accuracy: 0.1367\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.5117 - accuracy: 0.1384\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5204 - accuracy: 0.1331\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.4940 - accuracy: 0.1426\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.4642 - accuracy: 0.1491\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.4577 - accuracy: 0.1442\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.4619 - accuracy: 0.1433\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.4415 - accuracy: 0.1483\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.4294 - accuracy: 0.1493\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.4017 - accuracy: 0.1570\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.3784 - accuracy: 0.1598\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.4035 - accuracy: 0.1544\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.3356 - accuracy: 0.1680\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.3478 - accuracy: 0.1688\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.3579 - accuracy: 0.1611\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.2981 - accuracy: 0.1731\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.3162 - accuracy: 0.1728\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.2980 - accuracy: 0.1732\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.2529 - accuracy: 0.1836\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.2828 - accuracy: 0.1767\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.2318 - accuracy: 0.1819\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.2591 - accuracy: 0.1765\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.2289 - accuracy: 0.1857\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.2039 - accuracy: 0.1925\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.1761 - accuracy: 0.2023\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.1813 - accuracy: 0.1941\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.1522 - accuracy: 0.2043\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.1531 - accuracy: 0.1981\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 3.1101 - accuracy: 0.2097\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.1164 - accuracy: 0.2049\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.0796 - accuracy: 0.2159\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.0652 - accuracy: 0.2173\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.0867 - accuracy: 0.2148\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.0114 - accuracy: 0.2345\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.0118 - accuracy: 0.2388\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.0473 - accuracy: 0.2240\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.9734 - accuracy: 0.2351\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 2.9949 - accuracy: 0.2283\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.9926 - accuracy: 0.2303\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.9662 - accuracy: 0.2330\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.9452 - accuracy: 0.2448\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 2.9200 - accuracy: 0.2458\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 2.9073 - accuracy: 0.2585\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 2.9137 - accuracy: 0.2469\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.8720 - accuracy: 0.2600\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2.9023 - accuracy: 0.2509\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 2.8647 - accuracy: 0.2523\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.8708 - accuracy: 0.2613\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.8242 - accuracy: 0.2692\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.8254 - accuracy: 0.2694\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2.8353 - accuracy: 0.2693\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.7853 - accuracy: 0.2729\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.8009 - accuracy: 0.2694\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 2.7771 - accuracy: 0.2765\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 2.7622 - accuracy: 0.2793\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2.7583 - accuracy: 0.2778\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.7379 - accuracy: 0.2811\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.7382 - accuracy: 0.2803\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.7466 - accuracy: 0.2842\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6954 - accuracy: 0.2902\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.6784 - accuracy: 0.2989\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.7315 - accuracy: 0.2917\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6614 - accuracy: 0.3073\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6683 - accuracy: 0.3052\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.6583 - accuracy: 0.3028\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6604 - accuracy: 0.3051\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6103 - accuracy: 0.3103\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6280 - accuracy: 0.3066\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.6081 - accuracy: 0.3075\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.6148 - accuracy: 0.3145\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6202 - accuracy: 0.3073\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.5767 - accuracy: 0.3176\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.5702 - accuracy: 0.3243\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5377 - accuracy: 0.3282\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.5570 - accuracy: 0.3259\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5216 - accuracy: 0.3307\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5646 - accuracy: 0.3266\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4780 - accuracy: 0.3478\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5694 - accuracy: 0.3164\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5104 - accuracy: 0.3390\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.4829 - accuracy: 0.3346\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.5206 - accuracy: 0.3356\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4797 - accuracy: 0.3451\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4487 - accuracy: 0.3515\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.4613 - accuracy: 0.3416\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4377 - accuracy: 0.3494\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4396 - accuracy: 0.3455\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.4470 - accuracy: 0.3428\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4125 - accuracy: 0.3630\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.4483 - accuracy: 0.3440\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3813 - accuracy: 0.3611\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.3777 - accuracy: 0.3657\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3776 - accuracy: 0.3640\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.3960 - accuracy: 0.3607\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3429 - accuracy: 0.3723\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3844 - accuracy: 0.3666\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.3719 - accuracy: 0.3681\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.3450 - accuracy: 0.3683\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2792 - accuracy: 0.3874\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.3511 - accuracy: 0.3692\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2688 - accuracy: 0.3945\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2905 - accuracy: 0.3835\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2988 - accuracy: 0.3804\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2903 - accuracy: 0.3788\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3078 - accuracy: 0.3819\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2081 - accuracy: 0.4103\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2884 - accuracy: 0.3879\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2849 - accuracy: 0.3846\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2613 - accuracy: 0.3944\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2204 - accuracy: 0.3975\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2627 - accuracy: 0.3916\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2044 - accuracy: 0.4057\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2141 - accuracy: 0.4011\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2264 - accuracy: 0.3932\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.2185 - accuracy: 0.4069\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1959 - accuracy: 0.4049\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1648 - accuracy: 0.4149\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1666 - accuracy: 0.4039\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 2.2043 - accuracy: 0.4019\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1775 - accuracy: 0.4103\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1537 - accuracy: 0.4150\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.1398 - accuracy: 0.4174\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1316 - accuracy: 0.4213\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1601 - accuracy: 0.4165\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.1286 - accuracy: 0.4203\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.1226 - accuracy: 0.4216\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0820 - accuracy: 0.4312\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.0972 - accuracy: 0.4325\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0837 - accuracy: 0.4279\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1013 - accuracy: 0.4312\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0905 - accuracy: 0.4255\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0650 - accuracy: 0.4316\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0663 - accuracy: 0.4353\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0749 - accuracy: 0.4320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8fcd925580>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Text Generation with word2vec word Embediing"
      ],
      "metadata": {
        "id": "_YWNX6PnXdku"
      },
      "id": "_YWNX6PnXdku"
    },
    {
      "cell_type": "code",
      "source": [
        "word_model =gensim.models.Word2Vec(size=100, window=5, min_count=1, workers=8)\n",
        "word_model.build_vocab(seq)\n",
        "w2v_weights = word_model.wv.vectors\n",
        "vocab_size, embedding_size = w2v_weights.shape\n",
        "# vocab_size, embedding_size = pretrained_weights.shape\n",
        "print(\"Vocabulary Size: {} - Embedding Dim: {}\".format(vocab_size, embedding_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQRBCWuWk0q9",
        "outputId": "6859112a-7596-4a3c-d6f6-8c2208b1bec7"
      },
      "id": "UQRBCWuWk0q9",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2244 - Embedding Dim: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQgW8adP0MXw",
        "outputId": "ff21e0ff-a5f6-4f98-9a43-89699a2618f7"
      },
      "id": "sQgW8adP0MXw",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8477, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sentence_len = 46\n",
        "\n",
        "\n",
        "def word2idx(word):\n",
        "  print(word)\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx):\n",
        "  \n",
        "  return word_model.wv.index2word[idx]\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size+1, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if word in word_model.wv:\n",
        "    # weights of the words from word2vec weights\n",
        "    embedding_matrix[i] = word_model.wv[word]\n",
        "print(embedding_matrix.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO-UbHnGrAcw",
        "outputId": "4f2fb269-6f42-4838-8226-f4d306065e3c"
      },
      "id": "DO-UbHnGrAcw",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2245, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_model():\n",
        "  model = Sequential(name=\"w2v-textgeneration\")\n",
        "  model.add(Embedding(input_dim=vocab_size+1, output_dim=embedding_size, weights=[embedding_matrix], input_length=45))\n",
        "  model.add(LSTM(units=embedding_size))\n",
        "  model.add(Dense(units=vocab_size//8))\n",
        "  model.add(Dense(units=vocab_size//4))\n",
        "  model.add(Dense(units=vocab_size//2))\n",
        "  model.add(Dense(len(vocabulary_size)+1, activation='softmax'))\n",
        "  model.summary()\n",
        "  opt = RMSprop(lr=0.001)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "ziIgZvG2rAaV"
      },
      "id": "ziIgZvG2rAaV",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_model = w2v_model()\n",
        "word_model.fit(X, y, epochs=300, batch_size=256, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhVcy7v6x8lt",
        "outputId": "2089ce20-742c-4e0e-ecfc-e9fac11a5c88"
      },
      "id": "JhVcy7v6x8lt",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"w2v-textgeneration\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 45, 100)           224500    \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 280)               28280     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 561)               157641    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1122)              630564    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2245)              2521135   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,642,520\n",
            "Trainable params: 3,642,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "34/34 [==============================] - 2s 15ms/step - loss: 6.9750 - accuracy: 0.0461\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.3581 - accuracy: 0.0552\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.2030 - accuracy: 0.0547\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 6.0796 - accuracy: 0.0547\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.9268 - accuracy: 0.0541\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.7748 - accuracy: 0.0613\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.5938 - accuracy: 0.0840\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.3974 - accuracy: 0.0989\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 5.2269 - accuracy: 0.1142\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 5.0658 - accuracy: 0.1283\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.9109 - accuracy: 0.1436\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.7790 - accuracy: 0.1577\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.6589 - accuracy: 0.1708\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.5303 - accuracy: 0.1818\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.4400 - accuracy: 0.1903\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.3284 - accuracy: 0.2000\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4.2027 - accuracy: 0.2185\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4.0645 - accuracy: 0.2311\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.9417 - accuracy: 0.2458\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.7957 - accuracy: 0.2618\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.6849 - accuracy: 0.2690\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.5257 - accuracy: 0.2881\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.3952 - accuracy: 0.3019\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3.2387 - accuracy: 0.3203\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3.1203 - accuracy: 0.3334\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.9792 - accuracy: 0.3552\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.8674 - accuracy: 0.3677\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.7355 - accuracy: 0.3817\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.6293 - accuracy: 0.3980\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.4982 - accuracy: 0.4139\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.3674 - accuracy: 0.4369\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2.2398 - accuracy: 0.4612\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.1203 - accuracy: 0.4728\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.9625 - accuracy: 0.5073\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.8274 - accuracy: 0.5396\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.7103 - accuracy: 0.5614\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.5641 - accuracy: 0.5879\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.4675 - accuracy: 0.6074\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.3692 - accuracy: 0.6351\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.2862 - accuracy: 0.6574\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.1861 - accuracy: 0.6810\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.1044 - accuracy: 0.6982\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 1.0421 - accuracy: 0.7090\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.9505 - accuracy: 0.7376\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8805 - accuracy: 0.7538\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.8372 - accuracy: 0.7631\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8064 - accuracy: 0.7708\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.7186 - accuracy: 0.7957\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6997 - accuracy: 0.8015\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.8058\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6279 - accuracy: 0.8213\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5806 - accuracy: 0.8323\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.8301\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5282 - accuracy: 0.8455\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.4911 - accuracy: 0.8534\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4699 - accuracy: 0.8582\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.8663\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8760\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4182 - accuracy: 0.8742\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3805 - accuracy: 0.8852\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8870\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3531 - accuracy: 0.8929\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3275 - accuracy: 0.9021\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3291 - accuracy: 0.8965\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.9023\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2997 - accuracy: 0.9078\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2882 - accuracy: 0.9159\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2992 - accuracy: 0.9087\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2553 - accuracy: 0.9210\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2621 - accuracy: 0.9216\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2684 - accuracy: 0.9195\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2368 - accuracy: 0.9292\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2481 - accuracy: 0.9247\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2329 - accuracy: 0.9259\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2382 - accuracy: 0.9299\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2152 - accuracy: 0.9343\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2181 - accuracy: 0.9351\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2276 - accuracy: 0.9350\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2043 - accuracy: 0.9395\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.9368\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9402\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1810 - accuracy: 0.9472\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1805 - accuracy: 0.9443\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1870 - accuracy: 0.9405\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1747 - accuracy: 0.9476\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1592 - accuracy: 0.9515\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1720 - accuracy: 0.9473\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1717 - accuracy: 0.9525\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1548 - accuracy: 0.9488\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1519 - accuracy: 0.9533\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1591 - accuracy: 0.9520\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9580\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1414 - accuracy: 0.9605\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.9539\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.9574\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.9566\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.9594\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1268 - accuracy: 0.9650\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1244 - accuracy: 0.9633\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9607\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1167 - accuracy: 0.9654\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.9580\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9619\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1194 - accuracy: 0.9618\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1122 - accuracy: 0.9677\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1254 - accuracy: 0.9617\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9663\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1043 - accuracy: 0.9696\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1040 - accuracy: 0.9674\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1179 - accuracy: 0.9646\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1009 - accuracy: 0.9697\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1124 - accuracy: 0.9680\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0893 - accuracy: 0.9733\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9628\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0861 - accuracy: 0.9744\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0974 - accuracy: 0.9706\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0941 - accuracy: 0.9737\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0952 - accuracy: 0.9715\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9759\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9717\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0815 - accuracy: 0.9759\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1018 - accuracy: 0.9692\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0906 - accuracy: 0.9745\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0814 - accuracy: 0.9744\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0985 - accuracy: 0.9727\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9768\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0800 - accuracy: 0.9729\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9762\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9757\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0808 - accuracy: 0.9762\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0794 - accuracy: 0.9775\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0768 - accuracy: 0.9782\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0670 - accuracy: 0.9784\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9769\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.9771\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9778\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0850 - accuracy: 0.9770\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 0.9818\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.9817\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9752\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.9803\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9825\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0664 - accuracy: 0.9794\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0868 - accuracy: 0.9768\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9834\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0811 - accuracy: 0.9769\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.9818\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.9821\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9815\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0781 - accuracy: 0.9785\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9837\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9831\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9814\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0683 - accuracy: 0.9809\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0579 - accuracy: 0.9814\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9818\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.9838\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9851\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9837\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.9821\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0615 - accuracy: 0.9843\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 0.9841\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9849\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9841\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0542 - accuracy: 0.9825\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0423 - accuracy: 0.9878\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0579 - accuracy: 0.9838\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0429 - accuracy: 0.9850\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.9830\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.9850\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 0.9854\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.9857\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.9862\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.9857\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9857\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9894\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9835\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0557 - accuracy: 0.9860\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.9866\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0420 - accuracy: 0.9887\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0577 - accuracy: 0.9840\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9881\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0440 - accuracy: 0.9871\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0678 - accuracy: 0.9831\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9904\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.9868\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0443 - accuracy: 0.9888\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0495 - accuracy: 0.9873\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9893\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0488 - accuracy: 0.9866\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0488 - accuracy: 0.9870\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0405 - accuracy: 0.9890\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9921\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.9841\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9919\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9891\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9887\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0643 - accuracy: 0.9855\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9896\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.9854\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9910\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0487 - accuracy: 0.9877\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0492 - accuracy: 0.9856\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9915\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0440 - accuracy: 0.9894\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0503 - accuracy: 0.9887\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9909\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0430 - accuracy: 0.9896\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9873\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9887\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9900\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0370 - accuracy: 0.9909\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0411 - accuracy: 0.9921\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 0.9878\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9884\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9945\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9884\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9907\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0439 - accuracy: 0.9893\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9899\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0368 - accuracy: 0.9895\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 0.9893\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0458 - accuracy: 0.9893\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 0.9894\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0365 - accuracy: 0.9906\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0481 - accuracy: 0.9882\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9919\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.9917\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9917\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9910\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0365 - accuracy: 0.9910\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.9907\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 0.9909\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0453 - accuracy: 0.9920\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9943\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9906\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0413 - accuracy: 0.9910\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9917\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.9920\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9914\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 0.9904\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0356 - accuracy: 0.9914\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0430 - accuracy: 0.9927\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9922\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0488 - accuracy: 0.9902\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9929\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0350 - accuracy: 0.9908\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9933\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0379 - accuracy: 0.9920\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9922\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0363 - accuracy: 0.9921\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9919\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0363 - accuracy: 0.9916\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9928\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0439 - accuracy: 0.9914\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9937\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0364 - accuracy: 0.9899\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.9923\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9926\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9913\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9915\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9919\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9925\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9933\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9932\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9899\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0377 - accuracy: 0.9920\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 0.9930\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9929\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.9932\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9947\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.9915\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.9928\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 0.9930\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9962\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0375 - accuracy: 0.9930\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0359 - accuracy: 0.9928\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9926\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9947\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.9897\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9939\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 0.9908\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9943\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9917\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9935\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9940\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0353 - accuracy: 0.9925\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9934\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9933\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9930\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9917\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9940\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0295 - accuracy: 0.9926\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0355 - accuracy: 0.9920\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9928\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9921\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0353 - accuracy: 0.9942\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9940\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0420 - accuracy: 0.9927\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0310 - accuracy: 0.9943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8fcbaa2c40>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate text"
      ],
      "metadata": {
        "id": "MfDEUfRMAnRw"
      },
      "id": "MfDEUfRMAnRw"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        pred_word_ind = model.predict(pad_encoded, verbose=0)\n",
        "        pred_word_ind = np.argmax(pred_word_ind,axis=1)[0]\n",
        "        pred_word = tokenizer.index_word[pred_word_ind]\n",
        "        input_text += ' '+pred_word\n",
        "        output_text.append(pred_word)\n",
        "    return ' '.join(output_text)"
      ],
      "metadata": {
        "id": "AzgY2ojeq9vz"
      },
      "id": "AzgY2ojeq9vz",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(seq)"
      ],
      "metadata": {
        "id": "3Woxr2iqreAi"
      },
      "id": "3Woxr2iqreAi",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(50)\n",
        "random_pick = random.randint(0,len(seq))\n",
        "random_seed_text = seq[random_pick]\n"
      ],
      "metadata": {
        "id": "AI0o0aTyrEFF"
      },
      "id": "AI0o0aTyrEFF",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVZLJp1dshqu",
        "outputId": "28429795-87bd-4f3e-d220-673154384d70"
      },
      "id": "nVZLJp1dshqu",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2244,   20,  209, ...,    8,   10,    2],\n",
              "       [  20,  209,   46, ...,   10,    2,   84],\n",
              "       [ 209,   46,  247, ...,    2,   84,    5],\n",
              "       ...,\n",
              "       [  27,   62,   25, ..., 2243,    3,   25],\n",
              "       [  62,   25,    1, ...,    3,   25,  116],\n",
              "       [  25,    1,  308, ...,   25,  116,  737]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = ' '.join(random_seed_text)"
      ],
      "metadata": {
        "id": "CPEd7j0RsRro"
      },
      "id": "CPEd7j0RsRro",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Model Text Generation\n"
      ],
      "metadata": {
        "id": "scYIBQ1wc4kS"
      },
      "id": "scYIBQ1wc4kS"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(k_model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bSmJTSxSscd8",
        "outputId": "12b2b530-61b1-4039-a3cb-3fbe75d9a0cd"
      },
      "id": "bSmJTSxSscd8",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"coat of tropical tanning the multiply nor was welcome the difference in the bowsprit now i will eats done brown if any cut i please down i please i lighted a candle of the whale 's jaw coming belonging the soles of a bamboozingly story i furiously to planing away\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove Model Text Generation"
      ],
      "metadata": {
        "id": "9D6zlPtrdFov"
      },
      "id": "9D6zlPtrdFov"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(g_model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "XscSyuxhPFV9",
        "outputId": "76f5b6ad-94c9-4767-b629-6f466e1e1770"
      },
      "id": "XscSyuxhPFV9",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reasonest is boat keep the grand stranger a merchant leviathan mouth the bar looking spraining these the purty of darkness the town proved wherever a darkness implement mixed up the fountain money i is the frost small oh the docks door selling nigh the coach carted quiet capering the floor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Model Text Generation"
      ],
      "metadata": {
        "id": "t-JLdhS1Bts-"
      },
      "id": "t-JLdhS1Bts-"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(word_model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "X-DN6OIkqAvn",
        "outputId": "8a5e8d51-e1f6-4e38-ce27-a2f9ba3ca358"
      },
      "id": "X-DN6OIkqAvn",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stranded where else but from nantucket did those aboriginal whalemen the red men first sally out in canoes to give chase to the leviathan and where but from nantucket too did that first adventurous little sloop put forth partly laden with imported cobblestones so goes the story to throw at'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0fcZBQ9bYBKh"
      },
      "id": "0fcZBQ9bYBKh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}